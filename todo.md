# 数据分析任务清单

## 1. 数据集下载与初步了解
- [x] 下载并加载数据集（Demand, Metadata, Weather）。
- [x] 查看数据集的基本信息（行数、列名、数据类型）。
- [x] 阅读数据集的 `README.md`，理解字段含义。

## 2. 数据质量检查与初步分析
- [x] **数据量检查:** 确认各数据集的记录数。（Demand: ~2.38亿, Metadata: 7572, Weather: ~60.5万）
- [x] **缺失值分析:** 检查各列的缺失情况。（Demand: y有缺失, Metadata: 位置信息有缺失, Weather: 无缺失）
- [x] **重复值分析:** 检查是否存在基于关键列的重复记录。（Weather有少量重复，已处理）
- [x] **时间范围检查:** 确认数据的时间覆盖范围。（Demand: 2011-2017, Weather: 2011-2019）
- [x] **初步数据分布分析:**
    - [x] Demand (y) 分布：描述性统计（均值、中位数、分位数、最大值等），检查非正值。
    - [x] Metadata 分布：Building Class, Location, Freq 等分类特征分布。
    - [x] Weather 分布：Temperature, Humidity, Precipitation 等数值特征分布。
- [x] **初步关系分析:**
    - [x] Demand 与 Building Class 的关系（例如通过箱线图）。
    - [x] Demand 与 Weather 的关系（初步相关性）。
- [x] **时间戳频率分析:** 检查 Demand 和 Weather 的数据采样频率，并分析匹配性。

## 3. 数据清洗与预处理
- [x] 处理 Weather 数据中的重复记录。
- [x] 将不同频率的 Demand 数据重采样并聚合到统一的时间粒度（例如小时）。
- [x] 将 Demand, Metadata, Weather 数据进行合并。处理合并过程中因缺失导致的数据不匹配问题（例如 Location ID 缺失）。

## 4. 特征工程
- [x] 基于时间戳提取时间特征（年、月、日、星期几、小时等）。
- [x] 构建基于历史需求数据的滚动窗口统计特征（均值、标准差等）。
- [x] 处理特征工程后产生的缺失值（移除目标 y 缺失行，移除滚动特征初始窗口）。
- [x] 将构建好的特征集按年/月分区存储。

## 5. 模型训练准备 (下一步计划)
- [ ] **进一步处理合并后仍缺失天气数据的记录**（考虑插补策略或根据需要移除）。
- [ ] **考虑其他特征工程方法**（滞后特征、交互特征、分类特征编码、数值特征变换/归一化）。
- [ ] **划分数据集**（训练集、验证集、测试集），考虑时间序列数据的特性（时序交叉验证）。
- [ ] **选择预测模型**（统计模型、机器学习模型、深度学习模型等）。
- [ ] **定义评估指标**（RMSE, MAE, MAPE等）。
- [ ] **建立端到端的预测流程**（数据加载 -> 预处理 -> 特征工程 -> 模型训练 -> 预测 -> 评估）。

## 6. 模型训练与评估 (下一步计划)
- [ ] 在训练集上训练模型。
- [ ] 在验证集上调优模型参数。
- [ ] 在测试集上最终评估模型性能。
- [ ] 对模型结果进行分析和解释。

## 7. 报告撰写与展示 (下一步计划)
- [ ] 整理分析过程和结果，撰写报告或准备演示文稿（例如完善当前的 Beamer 报告）。
- [ ] 展示关键发现、模型性能等。

---
**日志记录和可视化说明:**
- 分析过程中，请确保使用 `loguru` 和自定义的 `log_utils.py` 记录关键步骤、数据量、缺失值、重复值等信息，日志文件保存在 `logs/` 目录下。
- 在数据分布、关系分析、时间序列特征等环节，尽可能生成图表并保存在 `plots/` 目录下，用于可视化展示。